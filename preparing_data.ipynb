{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with pitch type Other or NaN\n",
    "data = data[data['PITCH_NAME'] != \"Other\"]\n",
    "data = data.dropna(subset=['PITCH_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping to Pitch Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_mapping = {\n",
    "    '4-Seam Fastball': ['FB'],\n",
    "    'Slider': ['BB'],\n",
    "    'Sinker': ['FB'], # SHOULD THIS BE BREAKING TOO\n",
    "    'Knuckle Curve': ['BB'],\n",
    "    'Curveball': ['BB'],\n",
    "    'Changeup': ['OS'],\n",
    "    'Cutter': ['FB'],\n",
    "    'Sweeper': ['BB'],\n",
    "    'Split-Finger': ['OS'],\n",
    "    'Slurve': ['BB', 'OS'],\n",
    "    'Pitch Out': ['OS'],\n",
    "    'Slow Curve': ['BB', 'OS'],\n",
    "    'Eephus': ['OS'],\n",
    "    'Knuckleball': ['BB', 'OS'], # should this just be OS?? since knuckle curve is BB\n",
    "    'Forkball': ['OS', 'BB'],\n",
    "    'Screwball': ['BB'],\n",
    "}\n",
    "\n",
    "data['PITCH_GROUP'] = data['PITCH_NAME'].map(pitch_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PITCH_TYPE', 'PITCH_NAME', 'PLAYER_NAME', 'BATTER_ID', 'GAME_PK',\n",
       "       'GAME_YEAR', 'GAME_DATE', 'OUTS_WHEN_UP', 'BALLS', 'STRIKES', 'ON_1B',\n",
       "       'ON_2B', 'ON_3B', 'EVENTS', 'DESCRIPTION', 'TYPE', 'ZONE', 'PLATE_X',\n",
       "       'PLATE_Z', 'BB_TYPE', 'HIT_DISTANCE_SC', 'LAUNCH_SPEED', 'LAUNCH_ANGLE',\n",
       "       'ESTIMATED_BA_USING_SPEEDANGLE', 'ESTIMATED_WOBA_USING_SPEEDANGLE',\n",
       "       'WOBA_VALUE', 'BABIP_VALUE', 'ISO_VALUE', 'LAUNCH_SPEED_ANGLE',\n",
       "       'PITCH_GROUP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_keep = ['PITCH_TYPE', 'PITCH_NAME', 'PLAYER_NAME', 'BATTER_ID','GAME_PK', 'GAME_YEAR', 'GAME_DATE','OUTS_WHEN_UP', 'BALLS', 'STRIKES', 'ON_1B', 'ON_2B', 'ON_3B', 'EVENTS', 'DESCRIPTION', 'TYPE', 'ZONE', 'PLATE_X', 'PLATE_Z',\n",
    "'BB_TYPE', 'HIT_DISTANCE_SC','LAUNCH_SPEED', 'LAUNCH_ANGLE', 'ESTIMATED_BA_USING_SPEEDANGLE', 'ESTIMATED_WOBA_USING_SPEEDANGLE', 'WOBA_VALUE', 'BABIP_VALUE', 'ISO_VALUE', 'LAUNCH_SPEED_ANGLE',  'PITCH_GROUP']       \n",
    "data = data[cols_to_keep]\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Proportions for 2021-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PITCH_GROUP  BATTER_ID  %_FB_2021  %_BB_2021  %_OS_2021  %_FB_2022  %_BB_2022  \\\n",
      "0               444482  56.397875  26.798648  16.803477  53.271538  27.917121   \n",
      "1               453568  60.883721  23.209302  15.906977  61.600762  23.963792   \n",
      "2               456781  59.502262  30.693816   9.803922  57.845632  33.672604   \n",
      "3               457705  54.298056  34.384449  11.317495  58.045493  31.718618   \n",
      "4               457759  58.454693  31.674757   9.870550  62.995800  27.064862   \n",
      "\n",
      "PITCH_GROUP  %_OS_2022  %_FB_2023  %_BB_2023  %_OS_2023  \n",
      "0            18.811341  54.278250  26.649249  19.072502  \n",
      "1            14.435445  61.573770  23.672131  14.754098  \n",
      "2             8.481764  57.750420  30.945719  11.303861  \n",
      "3            10.235889  55.500496  32.210109  12.289395  \n",
      "4             9.939337  62.193309  28.736059   9.070632  \n"
     ]
    }
   ],
   "source": [
    "def calculate_pitch_type_percentages(df, year):\n",
    "    # Explode the PITCH_GROUP column to separate multiple groups\n",
    "    df_exploded = df.explode('PITCH_GROUP')\n",
    "    \n",
    "    # Count occurrences of each pitch group for each batter\n",
    "    pitch_group_counts = pd.crosstab(df_exploded['BATTER_ID'], df_exploded['PITCH_GROUP'])\n",
    "    \n",
    "    # Calculate total pitches for each batter\n",
    "    pitch_group_counts['total_pitches'] = pitch_group_counts.sum(axis=1)\n",
    "    \n",
    "    # Calculate percentages for each pitch group\n",
    "    for group in ['FB', 'BB', 'OS']:\n",
    "        pitch_group_counts[f'%_{group}_{year}'] = (pitch_group_counts.get(group, 0) / pitch_group_counts['total_pitches']) * 100\n",
    "    \n",
    "    # Keep only the percentage columns and BATTER_ID\n",
    "    return pitch_group_counts[[f'%_FB_{year}', f'%_BB_{year}', f'%_OS_{year}']].reset_index()\n",
    "\n",
    "# Filter data by year\n",
    "data_2021 = data[data['GAME_YEAR'] == 2021]\n",
    "data_2022 = data[data['GAME_YEAR'] == 2022]\n",
    "data_2023 = data[data['GAME_YEAR'] == 2023]  # New filter for 2023\n",
    "\n",
    "# Calculate percentages for 2021, 2022, and 2023\n",
    "percentages_2021 = calculate_pitch_type_percentages(data_2021, 2021)\n",
    "percentages_2022 = calculate_pitch_type_percentages(data_2022, 2022)\n",
    "percentages_2023 = calculate_pitch_type_percentages(data_2023, 2023)  # New calculation for 2023\n",
    "\n",
    "# Merge the three years together\n",
    "percents_by_year = pd.merge(percentages_2021, percentages_2022, on='BATTER_ID', how='outer', suffixes=('_2021', '_2022'))\n",
    "percents_by_year = pd.merge(percents_by_year, percentages_2023, on='BATTER_ID', how='outer')\n",
    "\n",
    "# Display the final dataframe\n",
    "print(percents_by_year.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort Original Data into Separate Dataframes by Pitch Group and Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the pitch group to handle multiple pitch group values in a list\n",
    "data_exploded = data.explode('PITCH_GROUP')\n",
    "\n",
    "# Function to filter data by year and pitch group\n",
    "def filter_by_pitch_group_and_year(df, pitch_group, year):\n",
    "    return df[(df['PITCH_GROUP'] == pitch_group) & (df['GAME_YEAR'] == year)]\n",
    "\n",
    "# Create six separate dataframes for each pitch group and year\n",
    "OS_2021 = filter_by_pitch_group_and_year(data_exploded, 'OS', 2021)\n",
    "BB_2021 = filter_by_pitch_group_and_year(data_exploded, 'BB', 2021)\n",
    "FB_2021 = filter_by_pitch_group_and_year(data_exploded, 'FB', 2021)\n",
    "\n",
    "OS_2022 = filter_by_pitch_group_and_year(data_exploded, 'OS', 2022)\n",
    "BB_2022 = filter_by_pitch_group_and_year(data_exploded, 'BB', 2022)\n",
    "FB_2022 = filter_by_pitch_group_and_year(data_exploded, 'FB', 2022)\n",
    "\n",
    "OS_2023 = filter_by_pitch_group_and_year(data_exploded, 'OS', 2023)\n",
    "BB_2023 = filter_by_pitch_group_and_year(data_exploded, 'BB', 2023)\n",
    "FB_2023 = filter_by_pitch_group_and_year(data_exploded, 'FB', 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Summary Stats by Year and Pitch Group for Each Player to Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_summary_statistics(df):\n",
    "    stats = df.groupby('BATTER_ID').agg(\n",
    "        PERC_FOUL=('DESCRIPTION', lambda x: (x == 'foul').mean() * 100),\n",
    "        PERC_SWINGING_STRIKE=('DESCRIPTION', lambda x: (x.isin(['swinging_strike', 'swinging_strike_blocked'])).mean() * 100),\n",
    "        PERC_HIT_INTO_PLAY=('DESCRIPTION', lambda x: (x == 'hit_into_play').mean() * 100),\n",
    "        AVG_WOBA_HIT_INTO_PLAY=('WOBA_VALUE', lambda x: x[df['DESCRIPTION'] == 'hit_into_play'].mean()),\n",
    "        PERC_EXTRA_BASE_HITS=('EVENTS', lambda x: (x.isin(['double', 'triple', 'home_run'])).mean() * 100),\n",
    "        AVG_LAUNCH_SPEED=('LAUNCH_SPEED', 'mean'),\n",
    "        AVG_LAUNCH_ANGLE=('LAUNCH_ANGLE', 'mean'),\n",
    "        PERC_PRODUCTIVE_CONTACT=('EVENTS', lambda x: (x.isin(['sac_fly', 'double', 'triple', 'single', 'home_run', 'sac_bunt'])).mean() * 100),\n",
    "        AVG_BABIP=('BABIP_VALUE', 'mean'),\n",
    "        AVG_ISO=('ISO_VALUE', 'mean')\n",
    "    ).reset_index()\n",
    "    \n",
    "    return stats\n",
    "\n",
    "PLAYER_STATS_OS_2021 = calculate_summary_statistics(OS_2021)\n",
    "PLAYER_STATS_BB_2021 = calculate_summary_statistics(BB_2021)\n",
    "PLAYER_STATS_FB_2021 = calculate_summary_statistics(FB_2021)\n",
    "\n",
    "PLAYER_STATS_OS_2022 = calculate_summary_statistics(OS_2022)\n",
    "PLAYER_STATS_BB_2022 = calculate_summary_statistics(BB_2022)\n",
    "PLAYER_STATS_FB_2022 = calculate_summary_statistics(FB_2022)\n",
    "\n",
    "PLAYER_STATS_OS_2023 = calculate_summary_statistics(OS_2023)\n",
    "PLAYER_STATS_BB_2023 = calculate_summary_statistics(BB_2023)\n",
    "PLAYER_STATS_FB_2023 = calculate_summary_statistics(FB_2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding More Descriptive ID Column for Merging Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the player stats dataframes with the updated names\n",
    "player_stats_dataframes = {\n",
    "    'PLAYER_STATS_OS_2021': PLAYER_STATS_OS_2021,\n",
    "    'PLAYER_STATS_BB_2021': PLAYER_STATS_BB_2021,\n",
    "    'PLAYER_STATS_FB_2021': PLAYER_STATS_FB_2021,\n",
    "    'PLAYER_STATS_OS_2022': PLAYER_STATS_OS_2022,\n",
    "    'PLAYER_STATS_BB_2022': PLAYER_STATS_BB_2022,\n",
    "    'PLAYER_STATS_FB_2022': PLAYER_STATS_FB_2022,\n",
    "    'PLAYER_STATS_OS_2023': PLAYER_STATS_OS_2023,\n",
    "    'PLAYER_STATS_BB_2023': PLAYER_STATS_BB_2023,\n",
    "    'PLAYER_STATS_FB_2023': PLAYER_STATS_FB_2023\n",
    "}\n",
    "\n",
    "# Loop through each player stats dataframe and add the 'ID' column\n",
    "for key, df in player_stats_dataframes.items():\n",
    "    pitch_group, year = key.split('_')[2:]  # Extract pitch group and year from the dataframe name\n",
    "    df['ID'] = df.apply(lambda row: f\"{pitch_group}_{year}_{row['BATTER_ID']}\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Columns for Percent of Pitch Type Received during Current and Following Year for Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BATTER_ID  PERC_FOUL  PERC_SWINGING_STRIKE  PERC_HIT_INTO_PLAY  \\\n",
      "0     444482  11.494253             14.367816           22.988506   \n",
      "1     453568  13.742690             12.280702           26.608187   \n",
      "2     456781  18.461538             12.307692           24.615385   \n",
      "3     457705  12.977099             15.648855           16.412214   \n",
      "4     457759  14.754098              7.786885           21.721311   \n",
      "\n",
      "   AVG_WOBA_HIT_INTO_PLAY  PERC_EXTRA_BASE_HITS  AVG_LAUNCH_SPEED  \\\n",
      "0                0.370000              2.873563         81.124138   \n",
      "1                0.312088              2.631579         83.044118   \n",
      "2                0.370312              2.307692         79.825926   \n",
      "3                0.255814              1.526718         81.956944   \n",
      "4                0.394340              1.639344         83.843373   \n",
      "\n",
      "   AVG_LAUNCH_ANGLE  PERC_PRODUCTIVE_CONTACT  AVG_BABIP   AVG_ISO  \\\n",
      "0          2.672414                 6.896552   0.221154  0.144231   \n",
      "1          6.448529                 7.602339   0.212389  0.123894   \n",
      "2         13.111111                 7.692308   0.243902  0.073171   \n",
      "3          0.027778                 3.435115   0.090909  0.121212   \n",
      "4         14.313253                 8.196721   0.232877  0.109589   \n",
      "\n",
      "               ID  PERC_RECEIVED  PERC_RECEIVED_FOLLOWING_YEAR  \n",
      "0  OS_2021_444482      16.803477                     18.811341  \n",
      "1  OS_2021_453568      15.906977                     14.435445  \n",
      "2  OS_2021_456781       9.803922                      8.481764  \n",
      "3  OS_2021_457705      11.317495                     10.235889  \n",
      "4  OS_2021_457759       9.870550                      9.939337  \n"
     ]
    }
   ],
   "source": [
    "# Add PERC_RECEIVED and PERC_RECEIVED_FOLLOWING_YEAR columns to each player stats dataframe\n",
    "for df_name, df in player_stats_dataframes.items():\n",
    "    pitch_group, year = df_name.split('_')[2:]  # Extract pitch group (OS, BB, FB) and year (2021, 2022, 2023)\n",
    "    year = int(year)  # Convert year to an integer\n",
    "\n",
    "    # Determine the correct percentage columns for the current year and the following year\n",
    "    perc_col_current_year = f'%_{pitch_group}_{year}'\n",
    "    perc_col_next_year = f'%_{pitch_group}_{year + 1}' if year != 2023 else None\n",
    "\n",
    "    # Map the current year's percentage received\n",
    "    df['PERC_RECEIVED'] = df['BATTER_ID'].map(percents_by_year.set_index('BATTER_ID')[perc_col_current_year])\n",
    "\n",
    "    # Map the following year's percentage received (for 2021 and 2022 only)\n",
    "    if year != 2023:\n",
    "        df['PERC_RECEIVED_FOLLOWING_YEAR'] = df['BATTER_ID'].map(percents_by_year.set_index('BATTER_ID')[perc_col_next_year])\n",
    "    else:\n",
    "        df['PERC_RECEIVED_FOLLOWING_YEAR'] = float('nan')  # Set NaN for 2023 since no following year exists\n",
    "\n",
    "# Example of how to access PLAYER_STATS_OS_2021 with the new columns\n",
    "print(PLAYER_STATS_OS_2021.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Accidental Duplicate Column and Export JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate BATTER_ID columns from each PLAYER_STATS dataframe\n",
    "for df_name, df in player_stats_dataframes.items():\n",
    "    if 'BATTER_ID' in df.columns:\n",
    "        # Drop duplicate BATTER_ID columns, keeping the first occurrence\n",
    "        df = df.loc[:, ~df.columns.duplicated()]\n",
    "        # Update the DataFrame in the dictionary\n",
    "        player_stats_dataframes[df_name] = df\n",
    "\n",
    "# Export each dataframe to a JSON file again\n",
    "for df_name, df in player_stats_dataframes.items():\n",
    "    df.to_json(f'{df_name}.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n",
      "269\n",
      "220\n"
     ]
    }
   ],
   "source": [
    "print(len(PLAYER_STATS_OS_2023))\n",
    "print(len(PLAYER_STATS_OS_2022))\n",
    "print(len(PLAYER_STATS_OS_2021))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaN Cleanup: if perc_hit_into_play = 0.0, remove nans in columns affected and fill with 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: PLAYER_STATS_FB_2021.json\n",
      "Processed and saved: PLAYER_STATS_FB_2022.json\n",
      "Processed and saved: PLAYER_STATS_FB_2023.json\n",
      "Processed and saved: PLAYER_STATS_BB_2021.json\n",
      "Processed and saved: PLAYER_STATS_BB_2022.json\n",
      "Processed and saved: PLAYER_STATS_BB_2023.json\n",
      "Processed and saved: PLAYER_STATS_OS_2021.json\n",
      "Processed and saved: PLAYER_STATS_OS_2022.json\n",
      "Processed and saved: PLAYER_STATS_OS_2023.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/nqklvy6x565bg7rjp1gqrcl40000gn/T/ipykernel_18021/4030030585.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# columns to check for nans\n",
    "nan_columns = ['AVG_ISO', 'AVG_BABIP', 'AVG_LAUNCH_SPEED', 'AVG_LAUNCH_ANGLE', 'AVG_WOBA_HIT_INTO_PLAY']\n",
    "\n",
    "# Function to process each dataframe\n",
    "def process_dataframe(df):\n",
    "    # Replace NaNs in the specified columns with 0 if 'PERC_HIT_INTO_PLAY' is 0.0\n",
    "    for col in nan_columns:\n",
    "        df.loc[(df['PERC_HIT_INTO_PLAY'] == 0.0) & (df[col].isna()), col] = 0.0\n",
    "    return df\n",
    "\n",
    "# List of JSON file paths\n",
    "json_files = [\n",
    "    'PLAYER_STATS_FB_2021.json', 'PLAYER_STATS_FB_2022.json', 'PLAYER_STATS_FB_2023.json',\n",
    "    'PLAYER_STATS_BB_2021.json', 'PLAYER_STATS_BB_2022.json', 'PLAYER_STATS_BB_2023.json',\n",
    "    'PLAYER_STATS_OS_2021.json', 'PLAYER_STATS_OS_2022.json', 'PLAYER_STATS_OS_2023.json'\n",
    "]\n",
    "\n",
    "# Iterate through the JSON files and process each one\n",
    "for json_file in json_files:\n",
    "    # Load the dataframe from JSON with lines=True\n",
    "    df = pd.read_json(json_file, lines=True)\n",
    "\n",
    "    # Process the dataframe (deal with NaNs)\n",
    "    df_processed = process_dataframe(df)\n",
    "\n",
    "    # Re-export the processed dataframe back to JSON with the same filename (lines=True to preserve structure)\n",
    "    df_processed.to_json(json_file, orient='records', lines=True)\n",
    "\n",
    "    print(f\"Processed and saved: {json_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('PLAYER_STATS.json', lines=True)\n",
    "\n",
    "# Process the dataframe (deal with NaNs)\n",
    "df_processed = process_dataframe(df)\n",
    "\n",
    "# Re-export the processed dataframe back to JSON with the same filename (lines=True to preserve structure)\n",
    "df_processed.to_json('PLAYER_STATS.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affirm NaNs have been removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [BATTER_ID, ID, PERC_RECEIVED, PERC_RECEIVED_FOLLOWING_YEAR, PERC_FOUL, PERC_SWINGING_STRIKE, PERC_HIT_INTO_PLAY, AVG_WOBA_HIT_INTO_PLAY, PERC_EXTRA_BASE_HITS, AVG_LAUNCH_SPEED, AVG_LAUNCH_ANGLE, PERC_PRODUCTIVE_CONTACT, AVG_BABIP, AVG_ISO]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('PLAYER_STATS.json', lines=True)\n",
    "nan_rows = df[(df.drop(columns=['PERC_RECEIVED_FOLLOWING_YEAR']).isna().any(axis=1))]\n",
    "print(nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load player stats dataframes for each pitch type and year from JSON files\n",
    "PLAYER_STATS_FB_2023 = pd.read_json('PLAYER_STATS_FB_2023.json', lines=True)\n",
    "PLAYER_STATS_BB_2023 = pd.read_json('PLAYER_STATS_BB_2023.json', lines=True)\n",
    "PLAYER_STATS_OS_2023 = pd.read_json('PLAYER_STATS_OS_2023.json', lines=True)\n",
    "\n",
    "PLAYER_STATS_FB_2022 = pd.read_json('PLAYER_STATS_FB_2022.json', lines=True)\n",
    "PLAYER_STATS_BB_2022 = pd.read_json('PLAYER_STATS_BB_2022.json', lines=True)\n",
    "PLAYER_STATS_OS_2022 = pd.read_json('PLAYER_STATS_OS_2022.json', lines=True)\n",
    "\n",
    "PLAYER_STATS_FB_2021 = pd.read_json('PLAYER_STATS_FB_2021.json', lines=True)\n",
    "PLAYER_STATS_BB_2021 = pd.read_json('PLAYER_STATS_BB_2021.json', lines=True)\n",
    "PLAYER_STATS_OS_2021 = pd.read_json('PLAYER_STATS_OS_2021.json', lines=True)\n",
    "\n",
    "\n",
    "player_stats = {\n",
    "    'FB': [PLAYER_STATS_FB_2023, PLAYER_STATS_FB_2022, PLAYER_STATS_FB_2021],\n",
    "    'BB': [PLAYER_STATS_BB_2023, PLAYER_STATS_BB_2022, PLAYER_STATS_BB_2021],\n",
    "    'OS': [PLAYER_STATS_OS_2023, PLAYER_STATS_OS_2022, PLAYER_STATS_OS_2021]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for NaN elements in FB dataframes:\n",
      "No NaN values found in FB for 2023.\n",
      "No NaN values found in FB for 2022.\n",
      "No NaN values found in FB for 2021.\n",
      "\n",
      "Checking for NaN elements in BB dataframes:\n",
      "No NaN values found in BB for 2023.\n",
      "No NaN values found in BB for 2022.\n",
      "No NaN values found in BB for 2021.\n",
      "\n",
      "Checking for NaN elements in OS dataframes:\n",
      "No NaN values found in OS for 2023.\n",
      "No NaN values found in OS for 2022.\n",
      "No NaN values found in OS for 2021.\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the dictionary and check for NaN elements in each dataframe, excluding PERC_RECEIVED_FOLLOWING_YEAR\n",
    "for pitch_type, df_list in player_stats.items():\n",
    "    print(f\"\\nChecking for NaN elements in {pitch_type} dataframes:\")\n",
    "    for i, df in enumerate(df_list):\n",
    "        # Get the year based on the position in the list (assuming the years are 2023, 2022, 2021)\n",
    "        year = 2023 - i\n",
    "        # Filter for NaN values, excluding PERC_RECEIVED_FOLLOWING_YEAR\n",
    "        nan_rows = df[(df.drop(columns=['PERC_RECEIVED_FOLLOWING_YEAR']).isna().any(axis=1))]\n",
    "        \n",
    "        if nan_rows.empty:\n",
    "            print(f\"No NaN values found in {pitch_type} for {year}.\")\n",
    "        else:\n",
    "            print(f\"\\nNaN values in {pitch_type} for {year} (excluding PERC_RECEIVED_FOLLOWING_YEAR):\")\n",
    "            print(nan_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**checking num of players each year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique players in 2021: 222\n",
      "Number of unique players in 2022: 270\n",
      "Number of unique players in 2023: 310\n"
     ]
    }
   ],
   "source": [
    "# Filter data by year\n",
    "data_2021 = data[data['GAME_YEAR'] == 2021]\n",
    "data_2022 = data[data['GAME_YEAR'] == 2022]\n",
    "data_2023 = data[data['GAME_YEAR'] == 2023]\n",
    "\n",
    "# Count unique BATTER_IDs in each year\n",
    "unique_players_2021 = data_2021['BATTER_ID'].nunique()\n",
    "unique_players_2022 = data_2022['BATTER_ID'].nunique()\n",
    "unique_players_2023 = data_2023['BATTER_ID'].nunique()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of unique players in 2021: {unique_players_2021}\")\n",
    "print(f\"Number of unique players in 2022: {unique_players_2022}\")\n",
    "print(f\"Number of unique players in 2023: {unique_players_2023}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
